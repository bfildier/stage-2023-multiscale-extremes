{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workings imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.getcwd()+'/src/')\n",
    "sys.path.insert(0, '/home/mcarenso/code/stage-2023-multiscale-extremes/scripts/src/')\n",
    "from myImports import *\n",
    "%matplotlib inline\n",
    "%load_ext autoreload"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filenames and global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'http://spiritx64-3:3080/'. Verify the server is running and reachable. (Forbidden)."
     ]
    }
   ],
   "source": [
    "stringSST = \"300\" ##295, 300 or 305\n",
    "n_days = 25\n",
    "chunk_size = {'time' :1, 'x' : 2048, 'y' : 128}\n",
    "label_chunk_size = {'time' :1, 'longitude' : 2048, 'latitude' : 128}\n",
    "\n",
    "#TOOCAN segmentation masks (les labels des objets MCS, dans la grille originale x,y,t)\n",
    "file_seg='/bdd/MT_WORKSPACE/MCS/RCE/SAM/TOOCAN/TOOCAN_v2022_04/irtb/TOOCAN_2.07_SAM_RCE_large'+stringSST+'_2D_irtb.nc'\n",
    "\n",
    "# TOOCAN objects (list d'objets MCS, leur labels et leur caractÃ©ristiques)\n",
    "file_tracking='/bdd/MT_WORKSPACE/MCS/RCE/SAM/TOOCAN/TOOCAN_v2022_04/irtb/FileTracking/TOOCAN-SAM_RCE_large'+stringSST+'_2D_irtb.dat.gz'\n",
    "\n",
    "sam_dir_path = \"/bdd/MT_WORKSPACE/REMY/RCEMIP/SAM/300K/\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precip dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.diskutils - INFO - Found stale lock file and directory '/home/mcarenso/dask-worker-space/worker-c7xmvkck', purging\n",
      "distributed.diskutils - INFO - Found stale lock file and directory '/home/mcarenso/dask-worker-space/worker-0b41cf_h', purging\n",
      "distributed.diskutils - INFO - Found stale lock file and directory '/home/mcarenso/dask-worker-space/worker-0pccjfhk', purging\n",
      "distributed.diskutils - INFO - Found stale lock file and directory '/home/mcarenso/dask-worker-space/worker-gz_lumiy', purging\n"
     ]
    }
   ],
   "source": [
    "# Open native precip datasets\n",
    "ds1 = xr.open_dataset(sam_dir_path+\"rcemip_large_2048x128x74_3km_12s_\"+stringSST+\"K_64.2Dcom_1.nc\")\n",
    "ds2 = xr.open_dataset(sam_dir_path+\"rcemip_large_2048x128x74_3km_12s_\"+stringSST+\"K_64.2Dcom_2.nc\")\n",
    "\n",
    "# Combine datasets\n",
    "ds = xr.concat([ds1, ds2], dim='time')\n",
    "# Rename dimensions\n",
    "ds[\"x\"] = ((ds[\"x\"])/3e3).astype(int)\n",
    "ds[\"y\"] = (ds[\"y\"]/3e3).astype(int) \n",
    "ds[\"time\"] = np.round(((ds[\"time\"]-75)*48)).astype(int)\n",
    "ds = ds.isel(time = slice(0, 48*n_days)) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import or Compute Precip Distrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 13\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     10\u001b[0m     \u001b[39m# File doesn't exist, create the object\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     dist_SAM_Prec \u001b[39m=\u001b[39m cs\u001b[39m.\u001b[39mDistribution(name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSAM Precipitation\u001b[39m\u001b[39m\"\u001b[39m, bintype \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39minvlogQ\u001b[39m\u001b[39m\"\u001b[39m, nd \u001b[39m=\u001b[39m \u001b[39m6\u001b[39m, fill_last_decade\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> 13\u001b[0m     dist_SAM_Prec\u001b[39m.\u001b[39mcomputeDistribution(sample \u001b[39m=\u001b[39m ds[\u001b[39m\"\u001b[39m\u001b[39mPrec\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mstack(flat\u001b[39m=\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mtime\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39my\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mx\u001b[39m\u001b[39m'\u001b[39m))\u001b[39m.\u001b[39mto_numpy())\n\u001b[1;32m     14\u001b[0m     dist_SAM_Prec\u001b[39m.\u001b[39mstoreSamplePoints(sample \u001b[39m=\u001b[39m ds[\u001b[39m\"\u001b[39m\u001b[39mPrec\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mstack(flat\u001b[39m=\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mtime\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39my\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mx\u001b[39m\u001b[39m'\u001b[39m))\u001b[39m.\u001b[39mto_numpy(), sizemax \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(\u001b[39m1e7\u001b[39m))\n\u001b[1;32m     16\u001b[0m     \u001b[39m# Save the object as a file\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ds' is not defined"
     ]
    }
   ],
   "source": [
    "filename = 'dist_SAM_Native_Prec_sizemax_1e7.pkl' # used for import or saving the object\n",
    "path = '/homedata/mcarenso/distrib/'  # my desired directory path\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.isfile(os.path.join(path, filename)):\n",
    "    # File exists, load the object\n",
    "    with open(os.path.join(path, filename), 'rb') as file:\n",
    "        dist_SAM_Prec = pickle.load(file)\n",
    "else:\n",
    "    # File doesn't exist, create the object\n",
    "\n",
    "    dist_SAM_Prec = cs.Distribution(name=\"SAM Precipitation\", bintype = \"invlogQ\", nd = 6, fill_last_decade=True)\n",
    "    dist_SAM_Prec.computeDistribution(sample = ds[\"Prec\"].stack(flat=('time', 'y', 'x')).to_numpy())\n",
    "    dist_SAM_Prec.storeSamplePoints(sample = ds[\"Prec\"].stack(flat=('time', 'y', 'x')).to_numpy(), sizemax = int(1e7))\n",
    "\n",
    "    # Save the object as a file\n",
    "    with open(os.path.join(path, filename), 'wb') as file:\n",
    "        pickle.dump(dist_SAM_Prec, file)\n",
    "        \n",
    "size = dist_SAM_Prec.size\n",
    "ds_SAM_shape = (size//(128*2048), 128, 2048)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import MCS data. List and Labels over (t,y,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import MCS list and prepare label list\n",
    "\n",
    "from load_TOOCAN_DYAMOND_modif_BenAndMax import load_TOOCAN_DYAMOND\n",
    "MCS = load_TOOCAN_DYAMOND(file_tracking)\n",
    "\n",
    "label_list = [MCS[i].label for i in range(len(MCS))]\n",
    "\n",
    "## function to retrieve the indexes in MCS by MCS labels, could be put in myFuncs but need label_list from the tracking file\n",
    "\n",
    "def idx_by_label(labels):\n",
    "    idxs = [label_list.index(label) for label in labels]\n",
    "    return idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mask = xr.open_dataarray(file_seg).isel(time=slice(48*n_days)).chunk(label_chunk_size)\n",
    "\n",
    "## function to retrieve the indexes in MCS by MCS labels, could be put in myFuncs but need label_list from the tracking file\n",
    "MCS_6h = [MCS[i] for i in range(len(MCS)) if MCS[i].duration in [12]] ## TODO : add the symetry if here\n",
    "MCS_6h_labels = [MCS_6h[i].label for i in range(len(MCS_6h))]\n",
    "\n",
    "def idx_by_label(labels, label_list = label_list):\n",
    "    idxs = [label_list.index(label) for label in labels]\n",
    "    return idxs\n",
    "\n",
    "# Put to nan the labels that are not in MCS_6h_labels\n",
    "label_6h_mask = label_mask.where(label_mask.isin(MCS_6h_labels))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precip Max over MCSs lifetimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pickle load Precip_max_over_lifetime if it exists \n",
    "filename = 'Precip_max_over_lifetime_MCS_6h.pkl' # used for import or saving the object\n",
    "path = '/homedata/mcarenso/data/'  # my desired directory path\n",
    "\n",
    "if os.path.isfile(os.path.join(path, filename)):\n",
    "    #load it \n",
    "    with open(os.path.join(path, filename), 'rb') as file:\n",
    "        Precip_max_over_lifetime = pickle.load(file)\n",
    "\n",
    "else:\n",
    "    ## We want to plot the maximim precip value found under MCS over its lifetime\n",
    "    Precip_max_over_lifetime = []\n",
    "\n",
    "    # I need fast acces to the precips so I will load them in memory\n",
    "    Prec = ds[\"Prec\"].load()\n",
    "\n",
    "    for mcs in MCS_6h : \n",
    "        lifetime = []\n",
    "        # get the label of the mcs \n",
    "        label = mcs.label\n",
    "        # use label_mask to get the indexes of the label over t,y,x # this looks bad...\n",
    "        mcs_idxs = np.where(label_6h_mask.compute() == label)\n",
    "        # for each time steps of the mcs which is the first element of the tuple mcs_idxs retrieve the max precip value\n",
    "        for t in np.unique(mcs_idxs[0]):\n",
    "            y_idx,x_idx  = np.array(mcs_idxs[1][mcs_idxs[0]==t]), np.array(mcs_idxs[2][mcs_idxs[0]==t])\n",
    "            max_precip = int(np.max(Prec[t,y_idx,x_idx]))\n",
    "            lifetime.append(max_precip)\n",
    "        \n",
    "        Precip_max_over_lifetime.append(lifetime)\n",
    "    #save it \n",
    "    with open(os.path.join(path, filename), 'wb') as file:\n",
    "        pickle.dump(Precip_max_over_lifetime, file)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get rid of empty list in Precip_max_over_lifetime\n",
    "Precip_max_over_lifetime = [l for l in Precip_max_over_lifetime if l != []]\n",
    "len(Precip_max_over_lifetime)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyLMD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
